name: Performance Benchmarks

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
    types: [opened, synchronize, labeled]
  schedule:
    # Run benchmarks weekly on Sunday at 3 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      benchmark_type:
        description: 'Type of benchmark to run'
        required: true
        default: 'quick'
        type: choice
        options:
        - quick
        - full
        - memory

permissions:
  contents: read
  checks: write
  pull-requests: write

jobs:
  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    if: contains(github.event.pull_request.labels.*.name, 'benchmark') || github.event_name == 'push' || github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    strategy:
      matrix:
        python-version: [3.12]
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-benchmark-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --no-interaction --no-root

    - name: Install project
      run: poetry install --no-interaction

    - name: Install benchmark dependencies
      run: |
        poetry add --group dev pytest-benchmark memory-profiler psutil

    - name: Create benchmark directory
      run: mkdir -p benchmark_results

    - name: Run performance benchmarks
      run: |
        BENCHMARK_TYPE="${{ github.event.inputs.benchmark_type || 'quick' }}"
        echo "Running $BENCHMARK_TYPE benchmarks..."
        
        case $BENCHMARK_TYPE in
          "quick")
            poetry run pytest tests/benchmarks/ -k "not slow" --benchmark-json=benchmark_results/quick_benchmarks.json
            ;;
          "full")
            poetry run pytest tests/benchmarks/ --benchmark-json=benchmark_results/full_benchmarks.json
            ;;
          "memory")
            poetry run pytest tests/benchmarks/ -k "memory" --benchmark-json=benchmark_results/memory_benchmarks.json
            ;;
        esac

    - name: Generate benchmark report
      run: |
        cat > benchmark_results/benchmark_summary.md << EOF
        # Performance Benchmark Results
        
        **Run Date:** $(date)
        **Commit:** ${{ github.sha }}
        **Branch:** ${{ github.ref_name }}
        **Python Version:** ${{ matrix.python-version }}
        
        ## Summary
        
        Benchmark results are available in the artifacts section.
        
        ## Key Metrics
        
        - Model inference time
        - Data loading performance
        - Memory usage patterns
        - Training step duration
        
        EOF

    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results-${{ matrix.python-version }}
        path: benchmark_results/

    - name: Comment PR with benchmark results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const path = './benchmark_results/benchmark_summary.md';
          if (fs.existsSync(path)) {
            const summary = fs.readFileSync(path, 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ðŸš€ Performance Benchmark Results\n\n${summary}`
            });
          }

  memory-profiling:
    name: Memory Profiling
    runs-on: ubuntu-latest
    if: contains(github.event.pull_request.labels.*.name, 'memory-profile') || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install Poetry
      uses: snok/install-poetry@v1

    - name: Install dependencies
      run: |
        poetry install --no-interaction
        poetry add --group dev memory-profiler matplotlib

    - name: Run memory profiling
      run: |
        mkdir -p memory_profiles
        poetry run python -m memory_profiler tests/profiling/memory_test.py > memory_profiles/memory_report.txt || echo "Memory profiling script not found"

    - name: Upload memory profiles
      uses: actions/upload-artifact@v3
      with:
        name: memory-profiles
        path: memory_profiles/