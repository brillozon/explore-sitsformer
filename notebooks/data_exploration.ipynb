{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\\n\n",
    "import matplotlib.pyplot as plt\\n\n",
    "import seaborn as sns\\n\n",
    "import torch\\n\n",
    "from pathlib import Path\\n\n",
    "\\n\n",
    "# Import SITS-Former modules\\n\n",
    "from sitsformer.data import DummySatelliteDataset, create_dataloader\\n\n",
    "from sitsformer.utils import load_config\\n\n",
    "\\n\n",
    "# Set up plotting\\n\n",
    "plt.style.use('default')\\n\n",
    "sns.set_palette('tab10')\\n\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a182c",
   "metadata": {},
   "source": [
    "## Load Configuration\\n\n",
    "\\n\n",
    "First, let's load the default configuration to understand the data parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\\n\n",
    "config_path = Path('../configs/default.yaml')\\n\n",
    "config = load_config(config_path)\\n\n",
    "\\n\n",
    "print('Data Configuration:')\\n\n",
    "for key, value in config['data'].items():\\n\n",
    "    print(f'  {key}: {value}')\\n\n",
    "    \\n\n",
    "print('\\\\nModel Configuration:')\\n\n",
    "for key, value in config['model'].items():\\n\n",
    "    print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20779507",
   "metadata": {},
   "source": [
    "## Create Dummy Dataset\\n\n",
    "\\n\n",
    "Let's create a dummy dataset for exploration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy dataset\\n\n",
    "dataset = DummySatelliteDataset(\\n\n",
    "    num_samples=1000,\\n\n",
    "    sequence_length=config['data']['sequence_length'],\\n\n",
    "    image_size=config['data']['image_size'],\\n\n",
    "    num_channels=config['model']['in_channels'],\\n\n",
    "    num_classes=config['model']['num_classes']\\n\n",
    ")\\n\n",
    "\\n\n",
    "print(f'Dataset size: {len(dataset)} samples')\\n\n",
    "print(f'Expected shape per sample: {dataset[0][0].shape}')\\n\n",
    "print(f'Data type: {dataset[0][0].dtype}')\\n\n",
    "print(f'Label range: {min(dataset[i][1] for i in range(100))} - {max(dataset[i][1] for i in range(100))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d3a2d",
   "metadata": {},
   "source": [
    "## Visualize Sample Data\\n\n",
    "\\n\n",
    "Let's examine a few samples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16391358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample\\n\n",
    "sample_idx = 42\\n\n",
    "images, label = dataset[sample_idx]\\n\n",
    "\\n\n",
    "print(f'Sample {sample_idx}:')\\n\n",
    "print(f'  Images shape: {images.shape}')  # (seq_len, channels, height, width)\\n\n",
    "print(f'  Label: {label}')\\n\n",
    "\\n\n",
    "# Extract dimensions\\n\n",
    "seq_len, channels, height, width = images.shape\\n\n",
    "\\n\n",
    "print(f'  Sequence length: {seq_len}')\\n\n",
    "print(f'  Number of channels: {channels}')\\n\n",
    "print(f'  Image size: {height}x{width}')\\n\n",
    "print(f'  Value range: [{images.min():.3f}, {images.max():.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ce025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first few time steps\\n\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\\n\n",
    "axes = axes.ravel()\\n\n",
    "\\n\n",
    "for i in range(8):\\n\n",
    "    # Take RGB channels (assuming first 3 are RGB-like)\\n\n",
    "    rgb_image = images[i, :3].permute(1, 2, 0)  # Convert to HWC\\n\n",
    "    \\n\n",
    "    # Normalize for display\\n\n",
    "    rgb_image = (rgb_image - rgb_image.min()) / (rgb_image.max() - rgb_image.min())\\n\n",
    "    \\n\n",
    "    axes[i].imshow(rgb_image)\\n\n",
    "    axes[i].set_title(f'Time Step {i}')\\n\n",
    "    axes[i].axis('off')\\n\n",
    "\\n\n",
    "plt.suptitle(f'Sample {sample_idx} - First 8 Time Steps (Pseudo-RGB)', fontsize=16)\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571a233",
   "metadata": {},
   "source": [
    "## Analyze Temporal Patterns\\n\n",
    "\\n\n",
    "Let's examine how pixel values change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random pixel and plot its temporal evolution\\n\n",
    "pixel_x, pixel_y = height//2, width//2  # Center pixel\\n\n",
    "\\n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\\n\n",
    "\\n\n",
    "# Plot different channels\\n\n",
    "channels_to_plot = [0, 1, 2, 3]  # First 4 channels\\n\n",
    "channel_names = ['Channel 0', 'Channel 1', 'Channel 2', 'Channel 3']\\n\n",
    "\\n\n",
    "for idx, (ax, channel, name) in enumerate(zip(axes.ravel(), channels_to_plot, channel_names)):\\n\n",
    "    temporal_data = images[:, channel, pixel_x, pixel_y].numpy()\\n\n",
    "    \\n\n",
    "    ax.plot(temporal_data, marker='o', linewidth=2, markersize=4)\\n\n",
    "    ax.set_title(f'{name} - Pixel ({pixel_x}, {pixel_y})')\\n\n",
    "    ax.set_xlabel('Time Step')\\n\n",
    "    ax.set_ylabel('Value')\\n\n",
    "    ax.grid(True, alpha=0.3)\\n\n",
    "    \\n\n",
    "plt.suptitle(f'Temporal Evolution - Sample {sample_idx}', fontsize=16)\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc628ef6",
   "metadata": {},
   "source": [
    "## Dataset Statistics\\n\n",
    "\\n\n",
    "Let's examine the distribution of labels and some basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c06bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect labels from a subset of the dataset\\n\n",
    "num_samples_to_check = 500\\n\n",
    "labels = [dataset[i][1] for i in range(num_samples_to_check)]\\n\n",
    "\\n\n",
    "# Plot label distribution\\n\n",
    "plt.figure(figsize=(12, 5))\\n\n",
    "\\n\n",
    "plt.subplot(1, 2, 1)\\n\n",
    "plt.hist(labels, bins=config['model']['num_classes'], alpha=0.7, edgecolor='black')\\n\n",
    "plt.title('Label Distribution')\\n\n",
    "plt.xlabel('Class')\\n\n",
    "plt.ylabel('Frequency')\\n\n",
    "plt.grid(True, alpha=0.3)\\n\n",
    "\\n\n",
    "# Calculate and display class distribution\\n\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\\n\n",
    "\\n\n",
    "plt.subplot(1, 2, 2)\\n\n",
    "plt.pie(counts, labels=[f'Class {i}' for i in unique_labels], autopct='%1.1f%%', startangle=90)\\n\n",
    "plt.title('Class Distribution')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()\\n\n",
    "\\n\n",
    "print('Class Distribution:')\\n\n",
    "for label, count in zip(unique_labels, counts):\\n\n",
    "    print(f'  Class {label}: {count} samples ({count/len(labels)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a514f",
   "metadata": {},
   "source": [
    "## Batch Processing\\n\n",
    "\\n\n",
    "Let's see how the data looks when processed in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04803ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data loader\\n\n",
    "batch_size = 8\\n\n",
    "dataloader = create_dataloader(\\n\n",
    "    dataset,\\n\n",
    "    batch_size=batch_size,\\n\n",
    "    shuffle=True,\\n\n",
    "    num_workers=0  # Use 0 for notebook compatibility\\n\n",
    ")\\n\n",
    "\\n\n",
    "# Get a batch\\n\n",
    "batch_images, batch_labels = next(iter(dataloader))\\n\n",
    "\\n\n",
    "print(f'Batch shape: {batch_images.shape}')  # (batch_size, seq_len, channels, height, width)\\n\n",
    "print(f'Batch labels: {batch_labels.numpy()}')\\n\n",
    "print(f'Batch labels shape: {batch_labels.shape}')\\n\n",
    "\\n\n",
    "# Calculate some batch statistics\\n\n",
    "print(f'\\\\nBatch Statistics:')\\n\n",
    "print(f'  Mean: {batch_images.mean().item():.4f}')\\n\n",
    "print(f'  Std: {batch_images.std().item():.4f}')\\n\n",
    "print(f'  Min: {batch_images.min().item():.4f}')\\n\n",
    "print(f'  Max: {batch_images.max().item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples from the batch\\n\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\\n\n",
    "\\n\n",
    "for i in range(batch_size):\\n\n",
    "    row = i // 4\\n\n",
    "    col = i % 4\\n\n",
    "    \\n\n",
    "    # Take the first time step and first 3 channels as pseudo-RGB\\n\n",
    "    sample_image = batch_images[i, 0, :3].permute(1, 2, 0)\\n\n",
    "    \\n\n",
    "    # Normalize for display\\n\n",
    "    sample_image = (sample_image - sample_image.min()) / (sample_image.max() - sample_image.min())\\n\n",
    "    \\n\n",
    "    axes[row, col].imshow(sample_image)\\n\n",
    "    axes[row, col].set_title(f'Sample {i}, Class {batch_labels[i].item()}')\\n\n",
    "    axes[row, col].axis('off')\\n\n",
    "\\n\n",
    "plt.suptitle('Batch Samples (First Time Step, Pseudo-RGB)', fontsize=16)\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee17d3",
   "metadata": {},
   "source": [
    "## Data Augmentation Preview\\n\n",
    "\\n\n",
    "If we had real satellite data, we could apply various augmentations. Let's simulate this with our dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52877dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate some basic augmentations\\n\n",
    "original_sample = batch_images[0]  # First sample from batch\\n\n",
    "\\n\n",
    "# Simple augmentations using PyTorch\\n\n",
    "import torch.nn.functional as F\\n\n",
    "\\n\n",
    "# Rotation (90 degrees)\\n\n",
    "rotated = torch.rot90(original_sample, 1, dims=(-2, -1))\\n\n",
    "\\n\n",
    "# Flip\\n\n",
    "flipped = torch.flip(original_sample, dims=(-1,))\\n\n",
    "\\n\n",
    "# Noise addition\\n\n",
    "noise_factor = 0.1\\n\n",
    "noisy = original_sample + torch.randn_like(original_sample) * noise_factor\\n\n",
    "\\n\n",
    "# Visualize original vs augmented (first time step, first 3 channels)\\n\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\\n\n",
    "\\n\n",
    "samples = [original_sample, rotated, flipped, noisy]\\n\n",
    "titles = ['Original', 'Rotated 90Â°', 'Horizontally Flipped', 'With Noise']\\n\n",
    "\\n\n",
    "for i, (sample, title) in enumerate(zip(samples, titles)):\\n\n",
    "    # Take first time step and first 3 channels\\n\n",
    "    img = sample[0, :3].permute(1, 2, 0)\\n\n",
    "    \\n\n",
    "    # Normalize for display\\n\n",
    "    img = (img - img.min()) / (img.max() - img.min())\\n\n",
    "    \\n\n",
    "    axes[i].imshow(img)\\n\n",
    "    axes[i].set_title(title)\\n\n",
    "    axes[i].axis('off')\\n\n",
    "\\n\n",
    "plt.suptitle('Data Augmentation Examples', fontsize=16)\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9b9a5",
   "metadata": {},
   "source": [
    "## Summary\\n\n",
    "\\n\n",
    "This notebook demonstrated:\\n\n",
    "\\n\n",
    "1. Loading configuration files\\n\n",
    "2. Creating dummy satellite image time series data\\n\n",
    "3. Visualizing temporal patterns\\n\n",
    "4. Analyzing dataset statistics\\n\n",
    "5. Working with data loaders for batch processing\\n\n",
    "6. Previewing potential data augmentations\\n\n",
    "\\n\n",
    "### Next Steps\\n\n",
    "\\n\n",
    "- Explore the model architecture in `model_architecture.ipynb`\\n\n",
    "- Run training experiments in `training_experiments.ipynb`\\n\n",
    "- Analyze results in `results_analysis.ipynb`\\n\n",
    "\\n\n",
    "### Working with Real Data\\n\n",
    "\\n\n",
    "When you have real satellite data:\\n\n",
    "\\n\n",
    "1. Replace `DummySatelliteDataset` with `SatelliteTimeSeriesDataset`\\n\n",
    "2. Provide the path to your data\\n\n",
    "3. Configure the appropriate data transforms\\n\n",
    "4. Adjust the configuration parameters to match your data dimensions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
